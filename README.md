# 2020-21 Ανάπτυξη Λογισμικού για Αλγοριθμικά προβλήματα - Project 2

* 1115201400190  Προκόπης Σταμελιάς
* 1115201600095  Άννα Λογοθέτη

* link στο Git: https://github.com/skagos/Project-Part2

* Χρησιμοποιήθηκε η έκδοση 2.4.3 του keras.

* Εκτέλεση autoencoder.py και classification.py όπως δείχνει η εκφώνηση.

## Τίτλος προγράμματος

Autoencoder και Classifier.

## Περιγραφή προγράμματος

Δημιουργία autoencoder και classifier μοντέλων και εκτέλεση πειραμάτων πάνω σε αυτά τα μοντέλα για εξάγωγη συμπερασμάτων.

## Αρχεία κώδικα

#### autoencoder.py:
Με τον κώδικα στο autoencoder.py δίνουμε στον χρήστη την δυνατότητα να δημιουργεί autoencoder μοντέλα, και στο τέλος της εκπαίδευσης κάθε μοντέλου ο χρήστης αποφασίζει αν θέλει να επαναλάβει την διαδικασία και να δημιουργήσει κάποιο άλλο autoencoder μοντέλο,αν θέλει να εμφανίσει τις γραφικές παραστάσεις σφάλματος ως προς τις υπερπαραμέτρους για τα εκτελεσθέντα πειράματα ή αν θέλει να αποθηκεύσει το τρέχον μοντέλο.

#### classification.py:
Με τον κώδικα στο classification.py δίνουμε στον χρήστη την δυνατότητα να δημιουργεί classifier μοντέλα χρησιμοποιώντας βάρη του encoder τμήματος ενός autoencoder μοντέλου. Στο τέλος κάθε εκπαίδευσης ο χρήστης αποφασίζει αν θέλει να επαναλάβει την διαδικασία και να δημιουργήσει κάποιο άλλο classifier μοντέλο, αν θέλει να εμφανίσει τις γραφικές παραστάσεις του σφάλματος και της ορθότητας καθώς επίσης και τους δείκτες αξιολόγησης για τα εκτελεσθέντα πειράματα, ή αν θέλει να κατηγοριοποιήσει με βάση το τρέχον μοντέλο τις εικόνες του test set (συνόλου ελέγχου).


## Αποτελέσματα πειραμάτων και συμπεράσματα

Το autoencoder.h5 είναι ένας προεκπαιδευμένος autoencoder που εκπαιδεύτηκε με τις εξής υπερπαραμέτρους(οι οποίες φαίνονται και στο info.txt γιατί, το autoencoder.h5 χρησιμοποιήθηκε και στο classification.py και εκεί χρειαζόμαστε τις υπερπαραμέτρους με τις οποίες φτιάχτηκε ο autoencoder.h5 για να φτιάξουμε τον κατηγοριοποιήτη):
* num of layers = 6
* x συντεταγμένη φίλτρου = 3
* y συντεταγμένη φίλτρου = 3
* Πλήθος φίλτρων ανά επίπεδο = [32 64 128 128 64 1]
* epochs = 10
* batch size = 128

Το classification.h5 είναι ένα προεκπαιδευμένο μοντέλο classifier (στο οποίο χρησιμοποιήθηκε το encoder κομμάτι του προεκπαιδευμένου μοντέλου autoencoder.h5) το οποίο εκπαιδεύτηκε για 10 epochs, 64 batch_size και 128 φίλτρα στο fully connected layer του classifier. Το αποτέλεσμα που έδωσε το μοντέλο classification.h5 για το test set(t10k-images.idx3-ubyte) ήταν το εξής:

> Found 9874 correct labels
> Found 126 incorrect labels

Και η κατηγοριοποίηση των εικόνων του test set (συγκεκριμένα 16 ενδεικτικές εικόνες για αυτές που κατηγοριοποιήθηκαν σωστά και 16 ενδεικτικές εικόνες για αυτές που κατηγοριοποιήθηκαν λάθος) φαίνεται στα αρχεία correctFC.png και incorrectFC.png.

Στο report.txt φαίνονται οι δείκτες αξιολόγησης για την κατηγοριοποιήση τριών πειραμάτων όπου είχαν batch_size = 64,filtersFC = 128 και το 1ο πείραμα είχε epochs = 5, το 2ο πείραμα είχε epochs = 15 και το 3ο πείραμα είχε epochs = 30(οι αντίστοιχες γραφικές παραστάσεις του σφάλματος και της ορθότητας φαίνονται στο αρχείο classifyEpochs.png).

Για την γραφική παράσταση του σφάλματος ως προς το πλήθος των εποχών (βλέπε το autoencoderEpochs.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με autoencoder μοντέλα,συμπεραίνω ότι:
Όσο αυξάνεται το πλήθος των εποχών, μειώνεται το σφάλμα(loss).

Για την γραφική παράσταση του σφάλματος ως προς το μέγεθος της δέσμης(batch size) (βλέπε τα αρχεία autoencoderBatchSize.png και autoencoderBatchSize2.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με autoencoder μοντέλα,συμπεραίνω ότι:
Όσο μειώνεται το batch size τόσο μειώνεται και το σφάλμα.

Για την γραφική παράσταση του σφάλματος ως προς το μέγεθος του φίλτρου (βλέπε το autoencoderFilterSize.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με autoencoder μοντέλα,συμπεραίνω ότι:
Το ιδανικότερο μέγεθος φίλτρου είναι το (3,3) γιατί, σύμφωνα με την αντίστοιχη γραφική παράσταση του αρχείου autoencoderFilterSize.png το (3,3) έχει την μικρότερη τιμή σφάλματος ενώ τα (2,2) και (5,5) έχουν υψηλότερες τιμές σφάλματος.

Για την γραφική παράσταση του σφάλματος ως προς το πλήθος των φίλτρων σε ένα επίπεδο (βλέπε το autoencoderFiltersPerLayer.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με autoencoder μοντέλα, συμπεραίνω ότι:
Όσο αυξάνουμε το πλήθος των φίλτρων σε ένα επίπεδο τόσο μειώνεται το σφάλμα.

Για την γραφική παράσταση του σφάλματος και της ορθότητας ως προς το πλήθος των εποχών (βλέπε το classifyEpochs.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με classifier μοντέλα, συμπεραίνω ότι:
Όσο αυξάνεται το πλήθος των εποχών, αυξάνεται η ορθότητα.
Όσο αυξάνεται το πλήθος των εποχών, μειώνεται το σφάλμα.

Για την γραφική παράσταση του σφάλματος και της ορθότητας ως προς το μέγεθος της δέσμης(batch size) (βλέπε το classifyBatchSize.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με classifier μοντέλα, δεν μπορώ να καταλήξω σε κάποιο συμπέρασμα γιατί το δείγμα τον πειραμάτων είναι μικρό και δεν μου δίνει κάποια σαφή αύξουσα ή φθίνουσα συνάρτηση.

Για την γραφική παράσταση του σφάλματος και της ορθότητας ως προς το πλήθος των φίλτρων στο fully connected layer (βλέπε το classifyFiltersFC.png) που προέκυψε από εκτέλεση διαδοχικών πειραμάτων με classifier μοντέλα, συμπεραίνω ότι:
Όσο αυξάνεται το πλήθος των φίλτρων, αυξάνεται η ορθότητα (για το training set).
Όσο αυξάνεται το πλήθος των φίλτρων, μειώνεται το σφάλμα (για το training set).
